<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> FlowMDM: Seamless Human Motion Composition with<br>Blended Positional Encodings | German Barquero </title> <meta name="author" content="German Barquero"> <meta name="description" content="FlowMDM"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, german, barquero, germanbarquero, hupba"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%98%80%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://barquerogerman.github.io/FlowMDM/"> </head> <body class=""> <nav class="navbar navbar-expand-lg navbar-light" role="navigation"> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav mx-auto"> <li class="nav-item"> <a class="nav-link" href="/"> <span class="icon"> <i class="fas fa-home"></i> </span> </a> </li> <li class="nav-item dropdown"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"> More Research </a> <div class="dropdown-menu" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/BeLFusion/"> BeLFusion (ICCV'23) </a> <a class="dropdown-item" href="/FlowMDM/"> FlowMDM (CVPR'24) </a> </div> </li> </ul> </div> </nav> <div class="container project_container mt-5"> <div class="post"> <header class="project-title" style="text-align: center; "> <h1 class="project-title title" style="font-weight: bold;"> <span class="gradient-text" style="background: linear-gradient(90deg, #ff0000, 15%, #00a1ff, 60%, #00D70C); -webkit-background-clip: text; color: transparent; font-size: 2.5rem">FlowMDM: Seamless Human Motion Composition with<br>Blended Positional Encodings</span> </h1> <p class="project-venue" style="font-size: 2.5em;">CVPR 2024</p> <h3> <a href="https://scholar.google.com/citations?user=pRC8DwcAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">German Barquero</a>, <a href="https://scholar.google.com/citations?user=oI6AIkMAAAAJ&amp;hl=en&amp;oi=ao" rel="external nofollow noopener" target="_blank">Sergio Escalera</a>, and <a href="https://scholar.google.com/citations?user=V0c9xx0AAAAJ&amp;hl=en&amp;oi=ao" rel="external nofollow noopener" target="_blank">Cristina Palmero</a> </h3> <h5>University of Barcelona and Computer Vision Center, Spain</h5> <div class="publications project-links"> <a href="https://arxiv.org/abs/2402.15509" class="btn" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="https://github.com/BarqueroGerman/FlowMDM" class="btn" role="button" target="_blank" rel="external nofollow noopener">Code</a> </div> </header> <div style="margin-top:20px"> <figure> <picture> <img src="/assets/img/flowmdm/teaser.png" class="figure-padding img-fluid rounded" width="100%" height="auto" title="teaser" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="d-flex align-items-center justify-content-center" style="margin-top: 30px; margin-bottom: 20px"> <div class="project-narrow" id="demo" style="text-align: justify;"> <h3 style="text-align: center;">🔥 Demo</h3> <figure> <video src="/assets/video/flowmdm/demo_flowmdm.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> </div> <div class="d-flex align-items-center justify-content-center" style="margin-top: 30px"> <div class="project-narrow" id="abstract" style="text-align: justify;"> <h3 style="text-align: center;">📌 Abstract</h3> <i> Conditional human motion generation is an important topic with many applications in virtual reality, gaming, and robotics. While prior works have focused on generating motion guided by text, music, or scenes, these typically result in isolated motions confined to short durations. Instead, we address the generation of long, continuous sequences guided by a series of varying textual descriptions. <br><br> In this context, we introduce <b>FlowMDM</b>, the first diffusion-based model that generates seamless Human Motion Compositions (HMC) without any postprocessing or redundant denoising steps. For this, we introduce the <b>Blended Positional Encodings</b>, a technique that leverages both absolute and relative positional encodings in the denoising chain. More specifically, global motion coherence is recovered at the absolute stage, whereas smooth and realistic transitions are built at the relative stage. As a result, we achieve state-of-the-art results in terms of accuracy, realism, and smoothness on the Babel and HumanML3D datasets. FlowMDM excels when trained with only a single description per motion sequence thanks to its <b>Pose-Centric Cross-ATtention</b>, which makes it robust against varying text descriptions at inference time. <br><br> Finally, to address the limitations of existing HMC metrics, we propose two new metrics: the Peak Jerk and the Area Under the Jerk, to detect abrupt transitions. </i> </div> </div> <div class="align-items-center" style="max-width: site.max_project_width; margin-top:50px; text-align: center;"> <h3 style="text-align: center; margin-bottom:20px">🎬 Human Motion Composition (🏃🏻‍♀️➜🚶🏻‍♀️➜🧎🏻‍♀️➜🧘🏻‍♀️)</h3> <div id="carouselCompositions" class="carousel slide" data-ride="carousel" data-interval="false"> <ol class="carousel-indicators"> <li data-target="#carouselCompositions" data-slide-to="0" class="active"> <li data-target="#carouselCompositions" data-slide-to="1"> <li data-target="#carouselCompositions" data-slide-to="2"> <li data-target="#carouselCompositions" data-slide-to="3"> <li data-target="#carouselCompositions" data-slide-to="4"> <li data-target="#carouselCompositions" data-slide-to="5"> <li data-target="#carouselCompositions" data-slide-to="6"> <li data-target="#carouselCompositions" data-slide-to="7"> </ol> <div class="carousel-inner"> <div class="carousel-item active"> <figure> <video src="/assets/video/flowmdm/babel_compo_CA.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_6B.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_CD.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_CC.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_CF.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_6A.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_CE.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_compo_CB.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> </div> <button class="carousel-control-prev" type="button" data-target="#carouselCompositions" data-slide="prev"> <span class="carousel-control-prev-icon" aria-hidden="true"></span> <span class="sr-only">Previous</span> </button> <button class="carousel-control-next" type="button" data-target="#carouselCompositions" data-slide="next"> <span class="carousel-control-next-icon" aria-hidden="true"></span> <span class="sr-only">Next</span> </button> </div> <div class="col-10" style="text-align: justify; display: inline-block; margin-top: -20px"> Solid curves match the trajectories of the <b style="color: blue">global position</b> (<b style="color: blue">blue</b>) and <b style="color: purple">left</b>/<b style="color: green">right</b> hands (<b style="color: purple">purple</b>/<b style="color: green">green</b>). Darker colors indicate instantaneous jerk deviations from the median value, saturating at twice the jerk's standard deviation in the dataset (<b>black segments</b>). Abrupt transitions manifest as black segments amidst lighter ones. </div> </div> <div style="max-width: site.max_project_width; margin-top:50px;"> <h3 style="text-align: center; margin-bottom:20px">🎬 Human Motion Extrapolation (🚶➜🚶➜🚶➜🚶)</h3> <div id="carouselExtrapolations" class="carousel slide" data-ride="carousel" data-interval="false"> <ol class="carousel-indicators"> <li data-target="#carouselExtrapolations" data-slide-to="0" class="active"> <li data-target="#carouselExtrapolations" data-slide-to="1"> <li data-target="#carouselExtrapolations" data-slide-to="2"> <li data-target="#carouselExtrapolations" data-slide-to="3"> </ol> <div class="carousel-inner"> <div class="carousel-item active"> <figure> <video src="/assets/video/flowmdm/babel_extra_6D.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_extra_6C.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_extra_CH.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> <div class="carousel-item"> <figure> <video src="/assets/video/flowmdm/babel_extra_CG.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" controls="" loop="" muted=""></video> </figure> </div> </div> <button class="carousel-control-prev" type="button" data-target="#carouselExtrapolations" data-slide="prev"> <span class="carousel-control-prev-icon" aria-hidden="true"></span> <span class="sr-only">Previous</span> </button> <button class="carousel-control-next" type="button" data-target="#carouselExtrapolations" data-slide="next"> <span class="carousel-control-next-icon" aria-hidden="true"></span> <span class="sr-only">Next</span> </button> </div> </div> <div class="d-flex align-items-center justify-content-center" style="margin-top: 0px"> <div class="project-narrow" id="motivations" style="text-align: justify;"> <h3 style="text-align: center;">🌟 Key contributions 🌟</h3> </div> </div> <div id="accordion" style="margin-top:20px"> <div class="card"> <div class="card-header" id="headingTwo" style="text-align: center; padding:0px"> <button class="btn btn-link collapsed dropdown-toggle" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo" style="font-size: 16px"> #1 - Blended positional encodings (BPE) </button> </div> <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordion"> <div class="card-body" style="text-align: center;"> <div style="text-align: justify;"> <b>Key observation:</b> at early denoising phases, motion diffusion models prioritize global inter-frame dependencies, shifting towards local relative dependencies as the process unfolds. </div> <figure> <picture> <img src="/assets/img/flowmdm/local_vs_global_attention.png" class="figure-padding rounded col-7" width="100%" height="auto" title="local_vs_global_att" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div style="margin-bottom: 20px; text-align: justify;"> The BPE exploits this observation to seamlessly build human motion compositions from different textual descriptions: <br> 1) <b>At early denoising stages</b>: absolute positional encodings + global attention restricted to each textual description. <br> 2) <b>At later denoising stages</b>: relative positional encodings + unrestricted windowed attention. <br><br> <b><u>Consequence</u></b>: intra-subsequence global dependencies are recovered at the beginning of the denoising, and intra- and inter-subsequences motion smoothness and realism are promoted later. <br> <b><u>How?</u></b> To make the model understand APE and RPE at inference, we expose it to both encodings by randomly alternating them during training. As a result, the BPE schedule can be tuned at inference time to balance the intra-subsequence coherence and the inter-subsequence realism trade-off. </div> </div> </div> </div> <div class="card"> <div class="card-header" id="headingOne" style="text-align: center; padding:0px;"> <button class="btn btn-link dropdown-toggle" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne" style="font-size: 16px"> #2 - Pose-centric cross-attention (PCCATT) </button> </div> <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accordion"> <div class="card-body"> <div class="row"> <div class="col-7"> <figure> <picture> <img src="/assets/img/flowmdm/arch.png" class="figure-padding img-fluid rounded" width="100%" height="auto" title="Motion" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-5" style="text-align: justify;"> The PCCATT minimizes the entanglement between the control signal (e.g., text, objects) and the noisy motion by feeding the former only to the query. Consequently, our model denoises each frame’s noisy pose only leveraging its own condition, and the neighboring noisy poses. <br><br> <b><u>Consequence</u></b>: the PCCATT makes our model robust against varying text descriptions at inference time, and it excels when trained with only a single description per motion sequence. → FlowMDM can be applied to <b>both supervised and unsupervised</b> human motion composition scenarios. </div> </div> </div> </div> </div> </div> <div class="d-flex align-items-center justify-content-center" style="margin-top: 50px;"> <div class="project-narrow" id="motivations" style="text-align: justify;"> <h3 style="text-align: center;">🥇 State-of-the-art composition and extrapolation 🥇</h3> </div> </div> <div class="card d-flex align-items-center justify-content-center" style="margin-top: 30px; padding:1rem"> <div style=""> <figure> <picture> <img src="/assets/img/flowmdm/qualitative_results.png" class="figure-padding img-fluid rounded" width="100%" height="auto" title="Qualitative Results" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div style="text-align: justify;"> Solid curves match the trajectories of the <b style="color: blue">global position</b> (<b style="color: blue">blue</b>) and <b style="color: purple">left</b>/<b style="color: green">right</b> hands (<b style="color: purple">purple</b>/<b style="color: green">green</b>). Darker colors indicate instantaneous jerk deviations from the median value, saturating at twice the jerk's standard deviation in the dataset (<b>black segments</b>). Abrupt transitions manifest as black segments amidst lighter ones. FlowMDM exhibits the most fluid motion and preserves the staticity or periodicity of extrapolated actions, in contrast to other methods that show spontaneous high jerk values and fail to keep the motion coherence in extrapolations. </div> </div> <div class="d-flex align-items-center justify-content-center" style="margin-top: 30px"> <div class="project-narrow" id="bibtex" style="text-align: justify;"> <h3 style="text-align: center;">🔗 BibTeX</h3> <div class="bibtex"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">barquero2024seamless</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Seamless Human Motion Composition with Blended Positional Encodings}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Barquero, German and Escalera, Sergio and Palmero, Cristina}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> <style>.carousel-control-next-icon{background-image:url("/assets/img/others/arrow_right_black.svg")!important}.carousel-control-prev-icon{background-image:url("/assets/img/others/arrow_left_black.svg")!important}.carousel-control-next-icon,.carousel-control-prev-icon{width:3rem!important;height:3rem!important}.carousel-control-next{justify-content:flex-end;width:fit-content!important}.carousel-control-prev{justify-content:flex-start;width:fit-content!important}.carousel-inner{margin-bottom:10%;width:90%;margin-left:5%}.carousel-indicators{bottom:-2.5rem}.carousel .carousel-indicators li{background-color:#777}</style> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script>$(function(){$(".dropdown-menu a").click(function(){var e=$(this).text();$(this).parent().parent().find(".selection").html(e)})});var prev_value=0,k_vals=[1,2,3,4,5,10,20,50];$(document).ready(function(){const e=$("#k_range");e.on("input change",()=>{e.val()!=prev_value&&(new_k_val=k_vals[e.val()],$("#k_range_val").text("k="+new_k_val),console.log("k="+new_k_val),$("#k-h36m").attr("src","/assets/img/belfusion/k_analysis/k_h36m_"+e.val()+".png"),$("#k-amass").attr("src","/assets/img/belfusion/k_analysis/k_amass_"+e.val()+".png")),prev_value=e.val()})}),document.addEventListener("DOMContentLoaded",function(){function e(){t&&clearTimeout(t),img_id=this.text,img=$("#"+img_id).children("img").get(0),$(img).hasClass("lazy")&&(t=setTimeout(function(){img.src=img.dataset.src,img.classList.remove("lazy")},20))}function a(){t&&clearTimeout(t),console.log($("#collapse-behavior-content"),$("#collapse-behavior-content").children("img")),imgs=$("#collapse-behavior-content").find("img"),t=setTimeout(function(){imgs.each(function(e){img=imgs[e],$(img).hasClass("lazy")&&(img.src=img.dataset.src,img.classList.remove("lazy"),clearTimeout(t))})},20)}var t,n=document.getElementsByClassName("dropdown-item"),i=document.getElementById("collapse-behavior");Array.from(n).forEach(a=>{a.addEventListener("click",e)}),i.addEventListener("click",a)});</script> </body> </html>